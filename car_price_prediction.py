# -*- coding: utf-8 -*-
"""Car_Price_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QQC6DIxDJXguOg79nPQiOqZCDRcC5FXI

# **Rajalakshmi Pillai**

# **Task 03**

# **DataSet Information:**

Car_ID: Unique id of each observation (Interger)

Symboling: Its assigned insurance risk rating, A value of +3 indicates 
that the auto is risky, -3 that it is probably pretty safe.(Categorical)

carCompany: Name of car company (Categorical)

fueltype: Car fuel type i.e gas or diesel (Categorical)

aspiration: Aspiration used in a car (Categorical)

doornumber: Number of doors in a car (Categorical)

carbody: body of car (Categorical)

drivewheel: type of drive wheel (Categorical)

enginelocation: Location of car engine (Categorical)

wheelbase: Weelbase of car (Numeric)

carlength: Length of car (Numeric)

carwidth: Width of car (Numeric)

carheight: height of car (Numeric)

curbweight: The weight of a car without occupants or baggage. (Numeric)

enginetype: Type of engine. (Categorical)

cylindernumber: cylinder placed in the car (Categorical)

enginesize: Size of car (Numeric)

fuelsystem: Fuel system of car (Categorical)

boreratio: Boreratio of car (Numeric)

stroke: Stroke or volume inside the engine (Numeric)

compressionratio: compression ratio of car (Numeric)

horsepower: Horsepower (Numeric)

peakrpm: car peak rpm (Numeric)

citympg: Mileage in city (Numeric)

highwaympg: Mileage on highway (Numeric)

price(Dependent variable): Price of car (Numeric)

# **Problem Statement:**

1. Based on the data, We have prediction / regression problem.

2. We wil make prediction on the target variable **PRICE**
And we will build a model to get best prediction on the price variable.

3. For that we will use **RMSE**(Root Mean Squared Error) and **R2**

**Imorting Important libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from datetime import datetime, timedelta

pd.options.display.float_format='{:.4f}'.format
plt.rcParams['figure.figsize'] = [8,8]
pd.set_option('display.max_columns', 500)
pd.set_option('display.max_colwidth', -1) 
sns.set(style='darkgrid')
import matplotlib.ticker as ticker
import matplotlib.ticker as plticker

"""**Import Dataset**"""

data = pd.read_csv("/content/CarPrice_Assignment.csv")
data.head()

"""# **Data Understanding**

**1.Dataset overview**
"""

data.info()

"""**2.Data Statistic**"""

data.describe()

"""**3.Variables DataType**"""

data.dtypes

"""# **Data Cleaning**

**3.Checking for null values**
"""

data.isnull().sum()

"""**Observation:**

There is no null values in our dataset

**4.Calculating the Missing Values % contribution in DF**
"""

df_null = data.isna().mean().round(4) * 100

df_null.sort_values(ascending=False).head()

"""**5.Outlier Analysis of target variable with maximum amount of Inconsistency**"""

outliers = ['price']
plt.rcParams['figure.figsize'] = [8,8]
sns.boxplot(data=data[outliers], orient="v",color='purple' ,whis=1.5,saturation=1, width=0.7)
plt.title("Outliers Variable Distribution", fontsize = 14, fontweight = 'bold')
plt.ylabel("Price Range", fontweight = 'bold')
plt.xlabel("Variable", fontweight = 'bold')
data.shape

"""**Observation:**

There are some price ranges above 36000 which can be termed as outliers but lets not remove it rather we will use standarization scaling.

**6.Unique Car company**
"""

data['CarName'].unique()

"""**Observation:**

I'll use only the brands/make not the models.

I have seen several typos, I'll handle those.

**7.Extracting Car Company from the CarName as per direction in Problem**
"""

data['model'] = [x.split()[0] for x in data['CarName']]

"""**Typo Error in Car Company name**

maxda = mazda

Nissan = nissan

porsche = porcshce

toyota = toyouta

vokswagen = volkswagen = vw

**8.Renaming the typo errors in Car Company names**
"""

data['model'] = data['model'].replace({'maxda': 'mazda', 'nissan': 'Nissan', 'porcshce': 'porsche', 'toyouta': 'toyota', 
                            'vokswagen': 'volkswagen', 'vw': 'volkswagen'})

data['model'].unique()

"""**9.Dropping car_ID and CarName Beacause no used in analysis**"""

data= data.drop(['car_ID','CarName'], axis=1)

"""**10 Checking for duplicates**"""

data.loc[data.duplicated()]

cat_col = data.select_dtypes(include=['object']).columns
num_col = data.select_dtypes(exclude=['object']).columns
df_cat = data[cat_col]
df_num = data[num_col]

"""# **Data Visualization**

**1.Visualizing the different car names available**
"""

plt.rcParams['figure.figsize'] = [15,8]
ax=data['model'].value_counts().plot(kind='bar',stacked=True,color='crimson')
ax.title.set_text('CarName')
plt.xlabel("Names of the Car",fontweight = 'bold')
plt.ylabel("Count of Cars",fontweight = 'bold')

"""**2.Visualizing the distribution of car prices**"""

plt.figure(figsize=(8,8))

plt.title('Car Price Distribution Plot')
sns.distplot(data['price'],color='olive')

"""The plots seems to be right skewed, the prices of almost all cars looks like less than 18000.

**3.Boxplot of all the categorical variables**
"""

plt.figure(figsize=(20, 15))
plt.subplot(3,3,1)
sns.boxplot(x = 'doornumber', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,2)
sns.boxplot(x = 'fueltype', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,3)
sns.boxplot(x = 'aspiration', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,4)
sns.boxplot(x = 'carbody', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,5)
sns.boxplot(x = 'enginelocation', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,6)
sns.boxplot(x = 'drivewheel', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,7)
sns.boxplot(x = 'enginetype', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,8)
sns.boxplot(x = 'cylindernumber', y = 'price', data = data,palette='rocket')
plt.subplot(3,3,9)
sns.boxplot(x = 'fuelsystem', y = 'price', data = data,palette='rocket')
plt.show()

"""**Observation:**

1. The cars with fueltype as diesel are comparatively expensive than the cars with fueltype as gas.

2. All the types of carbody is relatively cheaper as compared to convertible carbody.

3. The price of car is directly proportional to no. of cylinders in most cases.

4. The cars with rear enginelocation are way expensive than cars with front enginelocation.

5. Enginetype ohcv comes into higher price range cars.

6. DoorNumber isn't affecting the price much.
"""

plt.figure(figsize=(25, 6))

plt.subplot(1,3,1)
plt1 = data['cylindernumber'].value_counts().plot(kind='bar')
plt.title('Number of cylinders')
plt1.set(xlabel = 'Number of cylinders', ylabel='Frequency of Number of cylinders')


plt.subplot(1,3,2)
plt1 = data['fueltype'].value_counts().plot(kind='bar')
plt.title('Fuel Type')
plt1.set(xlabel = 'Fuel Type', ylabel='Frequency of Fuel type')

plt.subplot(1,3,3)
plt1 = data['carbody'].value_counts().plot(kind='bar')
plt.title('Car body')
plt1.set(xlabel = 'Car Body', ylabel='Frequency of Car Body')

"""**Observation:**

1. The number of cylinders used in most cars is four.
2. Number of Gas fueled cars are way more than diesel fueled cars.
3. Sedan is the most prefered car type.

**4. Relationship between variable**

**a. fuelsystem vs price with hue fueltype**
"""

plt.figure(figsize = (10, 6))
sns.boxplot(x = 'fuelsystem', y = 'price', hue = 'fueltype', data = data,palette='rocket')
plt.show()

"""**b. Carbody vs Price with hue enginelocation**"""

plt.figure(figsize = (10, 6))
sns.boxplot(x = 'cylindernumber', y = 'price', hue = 'fueltype', data = data,palette='rocket')
plt.show()

"""**c. Car Comapany VS Average Price**"""

plt.figure(figsize=(20, 6))

datax = pd.DataFrame(data.groupby(['model'])['price'].mean().sort_values(ascending = False))
datax.plot.bar(color='crimson')
plt.title('Car Company Name vs Average Price')
plt.show()

"""**Observation:**

**Jaguar,Buick and porsche** seems to have the highest average price.

**d. CarBody VS Average Price**
"""

plt.figure(figsize=(20, 6))

datax = pd.DataFrame(data.groupby(['carbody'])['price'].mean().sort_values(ascending = False))
datax.plot.bar(color='teal')
plt.title('CarBody Name vs Average Price')
plt.show()

"""**observation:**

**hardtop** and **convertible** seems to have the highest average price.

**5. Binning the Car Companies based on avg prices of each car Company.**
"""

data['price'] = data['price'].astype('int')
df_auto_temp = data.copy()
t = df_auto_temp.groupby(['model'])['price'].mean()
df_auto_temp = df_auto_temp.merge(t.reset_index(), how='left',on='model')
bins = [0,10000,20000,40000]
label =['Budget_Friendly','Medium_Range','TopNotch_Cars']
data['Cars_Category'] = pd.cut(df_auto_temp['price_y'],bins,right=False,labels=label)
data.head()

"""# **Significant variables after Visualization**

1. Cars_Category , Engine Type, Fuel Type
2. Car Body , Aspiration , Cylinder Number
3. Drivewheel , Curbweight , Car Length
4. Car Length , Car width , Engine Size
5. Boreratio , Horse Power , Wheel base
6. citympg , highwaympg , symboling

**Significant Variables**
"""

sig_col = ['price','Cars_Category','enginetype','fueltype', 'aspiration','carbody','cylindernumber', 'drivewheel',
            'wheelbase','curbweight', 'enginesize', 'boreratio','horsepower', 
                    'citympg','highwaympg', 'carlength','carwidth']

data= data[sig_col]
data

"""# **Data Preparation**

The variable **carbody** has five levels. We need to convert these levels into integer. Similarly we need to convert the categorical variables to numeric.

For this, we will use something called dummy variables.
"""

sig_cat_col = ['Cars_Category','fueltype','aspiration','carbody','drivewheel','enginetype','cylindernumber']

"""**Get the dummy variables for the categorical feature and store it in a new variable - 'dummies'**"""

dummies = pd.get_dummies(data[sig_cat_col])
dummies.shape

dummies = pd.get_dummies(data[sig_cat_col], drop_first = True)
dummies.shape

"""**Add the results to the original dataframe**"""

data = pd.concat([data, dummies], axis = 1)

"""**Drop the original cat variables as dummies are already created**"""

data.drop( sig_cat_col, axis = 1, inplace = True)
data.shape



"""# **Machine Learning**"""

# import all libraries and dependencies for machine learning
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.base import TransformerMixin
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression

from sklearn.metrics import r2_score,mean_squared_error

from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.feature_selection import SelectKBest,SelectPercentile,f_classif,f_regression,mutual_info_regression,mutual_info_classif,SelectFromModel,RFE

from xgboost import XGBRegressor
from xgboost import plot_importance

data

"""**Splitting the Data into Training and Testing Sets**"""

X= data.drop('price', axis=1)
y= data['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""#**Baseline Model- Liniear Regression**"""

model = LinearRegression()

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print (f'model : {model} and  rmse score is : {np.sqrt(mean_squared_error(y_test, y_pred))}, r2 score is {r2_score(y_test, y_pred)}')

"""# **Random Forest& Gradient Boosting & Extra Trees & XGBoost**"""

rmse_test =[]
r2_test =[]
model_names =[]
X= data.drop('price', axis=1)
y= data['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
rf = RandomForestRegressor(random_state=42)
gb = GradientBoostingRegressor(random_state=42)
et= ExtraTreesRegressor(random_state=42)
xgb = XGBRegressor(random_state=42)

models = [rf,gb,et,xgb]
for model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse_test.append(round(np.sqrt(mean_squared_error(y_test, y_pred)),2))
    r2_test.append(round(r2_score(y_test, y_pred),2))
    print (f'model : {model} and  rmse score is : {round(np.sqrt(mean_squared_error(y_test, y_pred)),2)}, r2 score is {round(r2_score(y_test, y_pred),4)}')

model_names = ['RandomForest','GradientBoost','ExtraTree','XGB']
result_df = pd.DataFrame({'RMSE':rmse_test,'R2_Test':r2_test}, index=model_names)
result_df

"""**Observation:**

1. Random forest, without any tuning got .94 R2 and lowest RMSE.

2. XGBoost also did a good job without any optimization / tuning.

# **Best Model with the Hyperparameter Tuning**
"""

X= data.drop('price', axis=1)
y= data['price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

rf = RandomForestRegressor(n_estimators= 220, random_state=42 )

rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
print (f' rmse score is : {round(np.sqrt(mean_squared_error(y_test, y_pred)),4)}, r2 score is {round(r2_score(y_test, y_pred),4)}')

"""**Observation:**

1. With hyperparameter tuning we got a lift.

2. RMSE (from 1984.44 to 1975.8483)

3. R2 (from .9432 to .9437)

# **Conclusion**

1. We have developed model to predict car price problem.

2. First, we made the detailed exploratory analysis.

3. We analyzed both target and features in detail.

4. We transform numerical variables to reduce skewness and get close to normal distribution.

5. We made hyperparameter tuning of the best model see the improvement

# **THANK YOU**
"""